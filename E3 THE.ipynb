{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b7d834d-8097-4be3-bb40-e186a3818867",
   "metadata": {},
   "source": [
    "## Start here ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "700606bc-4024-482f-abcc-5cfc5352240c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ[\"DGL_DISABLE_GRAPHBOLT\"] = \"1\"\n",
    "sys.path.append(\".\")\n",
    "import torch\n",
    "from networks import *\n",
    "from omegaconf import OmegaConf\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "from utils.data_utils import SE3Demo\n",
    "from utils.loss_utils import double_geodesic_distance_between_poses\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torch.utils.checkpoint as checkpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d72fe30-5c2f-4199-b6fd-5301906c98c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cfg = OmegaConf.load(f\"config/mug/pick/config.json\")\n",
    "cfg = all_cfg.mani\n",
    "cfg_seg = all_cfg.seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45312e50-32a1-44ba-8a98-4a37b83417b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "wd = os.path.join(\"experiments\", \"mug\", \"pick\")\n",
    "os.makedirs(wd, exist_ok=True)\n",
    "demo_path = os.path.join(\"data\", \"mug\", \"pick\", \"demo.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "702680e2-682b-4a93-8931-1f3d5f95edef",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "SE3Demo() takes no arguments",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m demo = \u001b[43mSE3Demo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdemo_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_aug\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata_aug\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maug_methods\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43maug_methods\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcpu\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m#demo = SE3Demo(demo_path, data_aug=True, aug_methods=0, device='cuda')  # maybe change the config file sometime\u001b[39;00m\n",
      "\u001b[31mTypeError\u001b[39m: SE3Demo() takes no arguments"
     ]
    }
   ],
   "source": [
    "demo = SE3Demo(demo_path, data_aug=cfg.data_aug, aug_methods=cfg.aug_methods, device=\"cpu\") \n",
    "#demo = SE3Demo(demo_path, data_aug=True, aug_methods=0, device='cuda')  # maybe change the config file sometime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f294868b-82d7-489b-b569-92ba785c367c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.data_aug, cfg.aug_methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3731ba72-69b6-49d4-b48c-0a5cd13d20c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo = SE3Demo(demo_path, data_aug=cfg.data_aug, aug_methods=cfg.aug_methods, device=\"cpu\") \n",
    "#demo = SE3Demo(demo_path, data_aug=True, aug_methods=0, device='cuda')  # maybe change the config file sometime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff420e83-67a8-4dae-8d0e-88e298353682",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(demo) * cfg.train_demo_ratio)\n",
    "test_size = len(demo) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(demo, [train_size, test_size])\n",
    "train_loader = DataLoader(train_dataset, batch_size=cfg.train_batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=cfg.test_batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ecd442-5403-44b9-870d-e991a97b889b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbd92dd-18bf-4102-b905-9cc0f333b5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b51115-b921-4890-9752-6bfaf5860509",
   "metadata": {},
   "outputs": [],
   "source": [
    "from networks.se3_backbone import SE3Backbone, ExtendedModule\n",
    "from networks.se3_transformer.model.fiber import Fiber\n",
    "from utils.data_utils import seg_pointcloud, random_dropout, mask_part_point_cloud\n",
    "\n",
    "from utils.vis import save_pcd_as_pcd\n",
    "from utils.data_utils import get_heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7928e8-d27d-4af9-a1c6-9d2e505bf073",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, device=\"cpu\", voxelize=True, voxel_size=0.01, radius_threshold=0.12, feature_point_radius=0.02):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.pos_net = SE3Backbone(\n",
    "            fiber_out=Fiber({\n",
    "                \"0\": 1, # one heatmap\n",
    "            }),\n",
    "            num_layers= 4,\n",
    "            num_degrees= 3,\n",
    "            num_channels= 8,\n",
    "            num_heads= 1,\n",
    "            channels_div= 2,\n",
    "            voxelize = voxelize,\n",
    "            voxel_size= voxel_size,\n",
    "            radius_threshold=radius_threshold,\n",
    "        )\n",
    "\n",
    "        self.ori_net = SE3Backbone(\n",
    "            fiber_out=Fiber({\n",
    "                \"1\": 3,\n",
    "            }),\n",
    "            num_layers= 4,\n",
    "            num_degrees= 4,\n",
    "            num_channels= 8,\n",
    "            num_heads= 1,\n",
    "            channels_div= 2,\n",
    "            voxelize = voxelize,\n",
    "            voxel_size= voxel_size,\n",
    "            radius_threshold=radius_threshold,\n",
    "        )\n",
    "        self.feature_point_radius = feature_point_radius\n",
    "        self.to(torch.device(self.device))\n",
    "        \n",
    "    def forward(self, inputs, train_pos=False, reference_point=None, distance_threshold=0.3, random_drop=False, draw_pcd=False, pcd_name=None, mask_part=False, save_ori_feature=False):\n",
    "        bs = inputs[\"xyz\"].shape[0]\n",
    "        new_inputs = {\n",
    "            \"xyz\": [],\n",
    "            \"rgb\": [],\n",
    "            \"feature\": []\n",
    "        }\n",
    "        gt_heatmaps = []\n",
    "        for i in range(bs):\n",
    "            if draw_pcd:\n",
    "                os.makedirs(\"pcd/mani\", exist_ok=True)\n",
    "                distances = torch.norm(inputs[\"xyz\"][i] - reference_point[i], dim=1)\n",
    "                closest_point_idx = torch.argmin(distances)\n",
    "                save_pcd_as_pcd(inputs[\"xyz\"][i], inputs[\"rgb\"][i], save_file=f\"pcd/mani/original_{pcd_name}_{i}.pcd\")\n",
    "\n",
    "                gt_heatmaps.append(get_heatmap(inputs[\"xyz\"][i], closest_point_idx, std_dev=0.015, max_value=1).to(self.pos_net.device))\n",
    "                save_pcd_as_pcd(inputs[\"xyz\"][i], gt_heatmaps[-1].unsqueeze(-1).repeat(1, 3)/torch.max(gt_heatmaps[-1]), save_file=f\"pcd/mani/gt_heatmap_{pcd_name}_{i}.pcd\", draw_heatmap=True)\n",
    "\n",
    "            if reference_point != None:\n",
    "                data = seg_pointcloud(inputs[\"xyz\"][i], inputs[\"rgb\"][i], reference_point[i], distance=distance_threshold)\n",
    "            else:\n",
    "                data = {\n",
    "                    \"xyz\": inputs[\"xyz\"][i],\n",
    "                    \"rgb\": inputs[\"rgb\"][i],\n",
    "                }\n",
    "            if random_drop:\n",
    "                data = random_dropout(data[\"xyz\"], data[\"rgb\"])\n",
    "            if mask_part:\n",
    "                data = mask_part_point_cloud(data[\"xyz\"], data[\"rgb\"])\n",
    "            new_inputs[\"xyz\"].append(data[\"xyz\"])\n",
    "            new_inputs[\"rgb\"].append(data[\"rgb\"])\n",
    "            new_inputs[\"feature\"].append(new_inputs[\"rgb\"][i])\n",
    "        inputs = new_inputs\n",
    "\n",
    "        # pos\n",
    "        if train_pos:\n",
    "            seg_output = self.pos_net(inputs)\n",
    "            xyz = seg_output[\"xyz\"]\n",
    "            feature = seg_output[\"feature\"]\n",
    "            pos_weights = []\n",
    "\n",
    "            output_pos = torch.zeros([len(xyz), 3]).to(self.device)\n",
    "            for i in range(len(xyz)):\n",
    "                if draw_pcd:\n",
    "                    save_pcd_as_pcd(xyz[i], feature[i][:, 0].clone().unsqueeze(-1).repeat(1, 3)/torch.max(feature[i][:, 0].clone()), save_file=f\"pcd/mani/pos_heatmap_{pcd_name}_{i}.pcd\", draw_heatmap=True)\n",
    "\n",
    "                pos_weight = torch.nn.functional.softmax(feature[i].reshape(-1, 1), dim=0).squeeze()\n",
    "                output_pos[i] = (xyz[i].T * pos_weight).T.sum(dim=0)\n",
    "                pos_weights.append(pos_weight)\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                seg_output = self.pos_net(inputs)\n",
    "                xyz = seg_output[\"xyz\"]\n",
    "                feature = seg_output[\"feature\"]\n",
    "                pos_weights = []\n",
    "\n",
    "                output_pos = torch.zeros([len(xyz), 3]).to(self.device)\n",
    "                for i in range(len(xyz)):\n",
    "                    if draw_pcd:\n",
    "                        save_pcd_as_pcd(xyz[i], feature[i][:, 0].clone().unsqueeze(-1).repeat(1, 3)/torch.max(feature[i][:, 0].clone()), save_file=f\"pcd/mani/pos_heatmap_{pcd_name}_{i}.pcd\", draw_heatmap=True)\n",
    "\n",
    "                    pos_weight = torch.nn.functional.softmax(feature[i].reshape(-1, 1), dim=0).squeeze()\n",
    "                    output_pos[i] = (xyz[i].T * pos_weight).T.sum(dim=0)\n",
    "                    pos_weights.append(pos_weight)\n",
    "\n",
    "        if draw_pcd:\n",
    "            for i in range(len(xyz)):\n",
    "                distances = torch.norm(xyz[i] - reference_point[i], dim=1)\n",
    "                closest_point_idx = torch.argmin(distances)\n",
    "                save_pcd_as_pcd(xyz[i], seg_output[\"given_graph\"][\"raw_node_feats\"][i][:, :3], save_file=f\"pcd/mani/ball_{pcd_name}_{i}.pcd\")\n",
    "\n",
    "        ori_output = self.ori_net(inputs)\n",
    "        xyz = ori_output[\"xyz\"]\n",
    "        feature = ori_output[\"feature\"]    # 3*3 = 9\n",
    "        output_ori = torch.zeros([len(xyz), 9]).to(self.device)\n",
    "\n",
    "        if save_ori_feature:\n",
    "            for i in range(len(xyz)):\n",
    "                torch.save(feature[i].cpu(), f\"pcd/mani/ori_feature_{pcd_name}_{i}.pt\")\n",
    "\n",
    "        for i in range(bs):\n",
    "            newdata = seg_pointcloud(xyz[i], xyz[i], reference_point=output_pos[i], distance=self.feature_point_radius, extra_data={\"feature\": feature[i]})\n",
    "            if newdata[\"xyz\"].shape[0] == 0:\n",
    "                # use the pos point\n",
    "                output_ori[i] = (feature[i].T * pos_weights[i].detach()).T.sum(dim=0)\n",
    "            else:\n",
    "                output_ori[i] = newdata[\"feature\"].mean(dim=0)\n",
    "\n",
    "        for i in range(3):\n",
    "            output_ori[:, 3*i:3*(i+1)] /= (torch.norm(output_ori[:, 3*i:3*(i+1)].clone(), dim=1).unsqueeze(1) + 1e-8)\n",
    "        return output_pos, output_ori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc10533d-ed2a-442c-b53d-a983cf1776e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8177ac9c-6389-4778-a955-bf7e790dcc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optm = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17216dc4-f07d-4884-b51e-74f6fab1bcfa",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a498bc7e-fab1-4a5a-b53f-4678119492a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#policy = globals()[cfg.model](voxel_size=cfg.voxel_size, radius_threshold=cfg.radius_threshold).float().to(cfg.device)\n",
    "#optm = torch.optim.Adam(policy.parameters(), lr=cfg.lr)\n",
    "scheduler = StepLR(optm, step_size=int(cfg.epoch/5), gamma=0.5)\n",
    "loss_fn = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65659304-93c1-41fd-bd6b-b405030a392c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b1b5bc-cd0b-47c6-a565-1e4fece191f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e820499-fb65-43cc-baa6-d9577e5e45ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(globals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e498e8c-3757-4812-a0df-80c1151791e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#user_defined = [var for var in globals() if not var.startswith('__')]\n",
    "#print(user_defined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f0d7fe-b970-416a-9b31-afe4ec5319bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248a0539-23e1-4896-8698-f680ec3fefa5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5171902-13b7-4913-a2ba-26af58539cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_test_loss = 1e5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889de0b0-4c96-48db-83c7-e4965f8211f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308eaa59-9da9-4e34-a79d-a97d356404f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "accumulation_steps = 2  # Accumulate gradients over 10 iterations\n",
    "optm.zero_grad()\n",
    "\n",
    "for epoch in range(5):\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch}/{cfg.epoch}\")\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for i, data in enumerate(progress_bar):\n",
    "        # Forward pass\n",
    "        output_pos = model(\n",
    "            {\"xyz\": data[\"xyz\"], \"rgb\": data[\"rgb\"]},\n",
    "            random_drop=cfg.random_drop,\n",
    "            draw_pcd=cfg.draw_pcd,\n",
    "            pcd_name=f\"{i}\",\n",
    "            mask_part=cfg.mask_part,\n",
    "        )\n",
    "        loss = loss_fn(output_pos, data[\"seg_center\"])\n",
    "        loss = loss / accumulation_steps  # Scale the loss appropriately\n",
    "        loss.backward()  # Accumulate gradients\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Every 10 iterations, update the model\n",
    "        if (i + 1) % accumulation_steps == 0:\n",
    "            optm.step()       # Update parameters\n",
    "            optm.zero_grad()  # Reset gradients for next accumulation\n",
    "            progress_bar.set_postfix(loss=running_loss)\n",
    "            running_loss = 0.0\n",
    "\n",
    "    scheduler.step()  # Optionally update learning rate at epoch end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b71cbc-78a3-4f5b-9ad0-fdfd647c7655",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(cfg.epoch):\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch}/{cfg.epoch}\")\n",
    "    policy.train()\n",
    "\n",
    "    for i, data in enumerate(progress_bar):\n",
    "        optm.zero_grad()\n",
    "\n",
    "        output_pos = policy(\n",
    "            {\"xyz\": data[\"xyz\"], \"rgb\": data[\"rgb\"]}, \n",
    "            random_drop=cfg.random_drop,\n",
    "            draw_pcd=cfg.draw_pcd,\n",
    "            pcd_name=f\"{i}\",\n",
    "            mask_part=cfg.mask_part,\n",
    "        )\n",
    "        loss = loss_fn(output_pos, data[\"seg_center\"])\n",
    "        loss.backward()\n",
    "        optm.step()\n",
    "\n",
    "        t_loss = torch.sqrt(torch.sum(torch.sqrt((output_pos-data[\"seg_center\"]) ** 2), dim=1)).mean()\n",
    "        progress_bar.set_postfix(loss=t_loss.item())\n",
    "\n",
    "    policy.eval()\n",
    "    with torch.no_grad():\n",
    "        test_loss = 0\n",
    "        for batch_idx, data in enumerate(test_loader):\n",
    "            output_pos = policy(\n",
    "                {\"xyz\": data[\"xyz\"], \"rgb\": data[\"rgb\"]}, \n",
    "                random_drop=False,\n",
    "                draw_pcd=cfg.draw_pcd,\n",
    "                pcd_name=f\"test_{batch_idx}\",\n",
    "            )\n",
    "            t_loss = torch.sqrt(torch.sum(torch.sqrt((output_pos-data[\"seg_center\"]) ** 2), dim=1)).mean()\n",
    "\n",
    "            test_loss += t_loss.item()\n",
    "        test_loss /= len(test_loader)\n",
    "        print(\"Epoch: \", epoch, \" seg test loss: \", test_loss)\n",
    "\n",
    "        if test_loss < best_test_loss:\n",
    "            best_test_loss = test_loss\n",
    "            torch.save(policy.state_dict(), os.path.join(wd, f\"segnet.pth\"))\n",
    "            print(\"Model saved!\")\n",
    "\n",
    "    scheduler.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51db25e6-290b-428d-8e1f-e6db918b174f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cf3f95-100c-4139-a605-794b282fd291",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
